{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Capstone_Server_Loading_File.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxLfDm4r9rzo",
        "outputId": "e57754a4-58d3-41a2-a133-2b12ea56dc7f"
      },
      "source": [
        "! pip install --upgrade category_encoders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 17.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW3-PlXbMVCj",
        "outputId": "c9b5ebcd-b3ec-4f63-8a44-1f1a27f37e92"
      },
      "source": [
        "!python -m nltk.downloader stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exnSzMfDNInq",
        "outputId": "6697e44a-faf4-4fb7-cf3a-bb01bb20f992"
      },
      "source": [
        "!python -m nltk.downloader punkt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE6nrG9CMY6L"
      },
      "source": [
        "from nltk.corpus import stopwords\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.corpus import stopwords\r\n",
        "import string\r\n",
        "import re\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhbzRuPT9ub_"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.preprocessing import OrdinalEncoder\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "import category_encoders \r\n",
        "from category_encoders.binary import BinaryEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll1zZizAE4Td"
      },
      "source": [
        "import json\r\n",
        "from os import listdir\r\n",
        "from os.path import isfile, join"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WasURJlJcKE"
      },
      "source": [
        "import pickle\r\n",
        "# Ignore the warnings\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWxK3jnnXoWs"
      },
      "source": [
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7de9U-IFaf1b"
      },
      "source": [
        "from datetime import datetime\r\n",
        "import calendar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA6YFIenoI0y",
        "outputId": "aabc65a8-5234-48f8-a638-69d9af6a4602"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAJXg_w3Ytb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "5e255619-a77f-4837-cbae-56e577b54bf8"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/NLP_Chatbot_Capstone_Project/data.csv')\r\n",
        "del df['Unnamed: 0'] \r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "      <th>Countries</th>\n",
              "      <th>Local</th>\n",
              "      <th>Industry Sector</th>\n",
              "      <th>Accident Level</th>\n",
              "      <th>Potential Accident Level</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Employee or Third Party</th>\n",
              "      <th>Critical Risk</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>Country_01</td>\n",
              "      <td>Local_01</td>\n",
              "      <td>Mining</td>\n",
              "      <td>I</td>\n",
              "      <td>IV</td>\n",
              "      <td>Male</td>\n",
              "      <td>Third Party</td>\n",
              "      <td>Pressed</td>\n",
              "      <td>While removing the drill rod of the Jumbo 08 f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-02 00:00:00</td>\n",
              "      <td>Country_02</td>\n",
              "      <td>Local_02</td>\n",
              "      <td>Mining</td>\n",
              "      <td>I</td>\n",
              "      <td>IV</td>\n",
              "      <td>Male</td>\n",
              "      <td>Employee</td>\n",
              "      <td>Pressurized Systems</td>\n",
              "      <td>During the activation of a sodium sulphide pum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-06 00:00:00</td>\n",
              "      <td>Country_01</td>\n",
              "      <td>Local_03</td>\n",
              "      <td>Mining</td>\n",
              "      <td>I</td>\n",
              "      <td>III</td>\n",
              "      <td>Male</td>\n",
              "      <td>Third Party (Remote)</td>\n",
              "      <td>Manual Tools</td>\n",
              "      <td>In the sub-station MILPO located at level +170...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-08 00:00:00</td>\n",
              "      <td>Country_01</td>\n",
              "      <td>Local_04</td>\n",
              "      <td>Mining</td>\n",
              "      <td>I</td>\n",
              "      <td>I</td>\n",
              "      <td>Male</td>\n",
              "      <td>Third Party</td>\n",
              "      <td>Others</td>\n",
              "      <td>Being 9:45 am. approximately in the Nv. 1880 C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-10 00:00:00</td>\n",
              "      <td>Country_01</td>\n",
              "      <td>Local_04</td>\n",
              "      <td>Mining</td>\n",
              "      <td>IV</td>\n",
              "      <td>IV</td>\n",
              "      <td>Male</td>\n",
              "      <td>Third Party</td>\n",
              "      <td>Others</td>\n",
              "      <td>Approximately at 11:45 a.m. in circumstances t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>2017-07-04 00:00:00</td>\n",
              "      <td>Country_01</td>\n",
              "      <td>Local_04</td>\n",
              "      <td>Mining</td>\n",
              "      <td>I</td>\n",
              "      <td>III</td>\n",
              "      <td>Male</td>\n",
              "      <td>Third Party</td>\n",
              "      <td>Others</td>\n",
              "      <td>Being approximately 5:00 a.m. approximately, w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>2017-07-04 00:00:00</td>\n",
              "      <td>Country_01</td>\n",
              "      <td>Local_03</td>\n",
              "      <td>Mining</td>\n",
              "      <td>I</td>\n",
              "      <td>II</td>\n",
              "      <td>Female</td>\n",
              "      <td>Employee</td>\n",
              "      <td>Others</td>\n",
              "      <td>The collaborator moved from the infrastructure...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>2017-07-05 00:00:00</td>\n",
              "      <td>Country_02</td>\n",
              "      <td>Local_09</td>\n",
              "      <td>Metals</td>\n",
              "      <td>I</td>\n",
              "      <td>II</td>\n",
              "      <td>Male</td>\n",
              "      <td>Employee</td>\n",
              "      <td>Venomous Animals</td>\n",
              "      <td>During the environmental monitoring activity i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>2017-07-06 00:00:00</td>\n",
              "      <td>Country_02</td>\n",
              "      <td>Local_05</td>\n",
              "      <td>Metals</td>\n",
              "      <td>I</td>\n",
              "      <td>II</td>\n",
              "      <td>Male</td>\n",
              "      <td>Employee</td>\n",
              "      <td>Cut</td>\n",
              "      <td>The Employee performed the activity of strippi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>2017-07-09 00:00:00</td>\n",
              "      <td>Country_01</td>\n",
              "      <td>Local_04</td>\n",
              "      <td>Mining</td>\n",
              "      <td>I</td>\n",
              "      <td>II</td>\n",
              "      <td>Female</td>\n",
              "      <td>Third Party</td>\n",
              "      <td>Fall prevention (same level)</td>\n",
              "      <td>At 10:00 a.m., when the assistant cleaned the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>425 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Data  ...                                        Description\n",
              "0    2016-01-01 00:00:00  ...  While removing the drill rod of the Jumbo 08 f...\n",
              "1    2016-01-02 00:00:00  ...  During the activation of a sodium sulphide pum...\n",
              "2    2016-01-06 00:00:00  ...  In the sub-station MILPO located at level +170...\n",
              "3    2016-01-08 00:00:00  ...  Being 9:45 am. approximately in the Nv. 1880 C...\n",
              "4    2016-01-10 00:00:00  ...  Approximately at 11:45 a.m. in circumstances t...\n",
              "..                   ...  ...                                                ...\n",
              "420  2017-07-04 00:00:00  ...  Being approximately 5:00 a.m. approximately, w...\n",
              "421  2017-07-04 00:00:00  ...  The collaborator moved from the infrastructure...\n",
              "422  2017-07-05 00:00:00  ...  During the environmental monitoring activity i...\n",
              "423  2017-07-06 00:00:00  ...  The Employee performed the activity of strippi...\n",
              "424  2017-07-09 00:00:00  ...  At 10:00 a.m., when the assistant cleaned the ...\n",
              "\n",
              "[425 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13m0lm19Z6Um"
      },
      "source": [
        "# temp_test_entry={\r\n",
        "#     'Data':'2016-01-01 00:00:00',\r\n",
        "#     'Countries':'Country_01',\r\n",
        "#     'Local':'Local_01',\r\n",
        "#     'Industry Sector':'Mining',\r\n",
        "#     'Accident Level': 'I',\r\n",
        "#     'Potential Accident Level':'IV',\r\n",
        "#     'Genre':'Male',\r\n",
        "#     'Employee or Third Party':'Third Party',\r\n",
        "#     'Critical Risk':'Pressed',\r\n",
        "#     'Description':'While removing the drill rod of the Jumbo 08 for maintenance, the supervisor proceeds to loosen the support of the intermediate centralizer to facilitate the removal, seeing this the mechanic supports one end on the drill of the equipment to pull with both hands the bar and accelerate the removal from this, at this moment the bar slides from its point of support and tightens the fingers of the mechanic between the drilling bar and the beam of the jumbo.',\r\n",
        "# }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khTaQ_ee0WrE",
        "outputId": "de4940c0-99fd-4127-dc7d-055db09f58c3"
      },
      "source": [
        "user_dict =  json.loads(open('user_data.json').read())\r\n",
        "user_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CountryName': 'Country_01',\n",
              " 'CriticalRisk': 'Pressed',\n",
              " 'Description': 'While removing the drill rod of the Jumbo 08 for maintenance, the supervisor proceeds to loosen the support of the intermediate centralizer to facilitate the removal, seeing this the mechanic supports one end on the drill of the equipment to pull with both hands the bar and accelerate the removal from this, at this moment the bar slides from its point of support and tightens the fingers of the mechanic between the drilling bar and the beam of the jumbo.',\n",
              " 'Employment Type': 'Third Party',\n",
              " 'Gender': 'Male',\n",
              " 'IncidentDate': '2016-01-01  12:00:00',\n",
              " 'IndustrialSector': 'Mining',\n",
              " 'Location': 'Local_01',\n",
              " 'Potential Accident Level': 'IV'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3X7tac6ZZ7F"
      },
      "source": [
        "temp_test_entry={}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NuGSqKb0KpH"
      },
      "source": [
        "temp_test_entry={}\r\n",
        "temp_test_entry['Description'] = user_dict['Description']\r\n",
        "temp_test_entry['Critical Risk'] = user_dict['CriticalRisk']\r\n",
        "temp_test_entry['Data'] = user_dict['IncidentDate']\r\n",
        "temp_test_entry['Countries'] = user_dict['CountryName']\r\n",
        "temp_test_entry['Local'] = user_dict['Location']\r\n",
        "temp_test_entry['Industry Sector'] = user_dict['IndustrialSector']\r\n",
        "temp_test_entry['Genre'] = user_dict['Gender']\r\n",
        "temp_test_entry['Employee or Third Party'] = user_dict['Employment Type']\r\n",
        "temp_test_entry['Potential Accident Level'] = user_dict['Potential Accident Level']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9DrBHNrZFjE"
      },
      "source": [
        "# for i in range(0,len(df.columns)):\r\n",
        "#   temp_test_entry[df.columns[i]]=df.iloc[20][i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBLitKfXZZhB"
      },
      "source": [
        "date_event=datetime.strptime(temp_test_entry['Data'], '%Y-%m-%d %H:%M:%S')\r\n",
        "temp_test_entry['Date of Incidents']=date_event\r\n",
        "temp_test_entry['Year of Incident'],temp_test_entry['Month of Incident']=date_event.year,date_event.month\r\n",
        "temp_test_entry['Date of Incident'],temp_test_entry['Day of Incident']=date_event.day,calendar.day_name[date_event.weekday()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ1c0X7BcXW4"
      },
      "source": [
        "path_initial_encoders='/content/drive/MyDrive/NLP_Chatbot_Capstone_Project/Initial Encoders'\r\n",
        "path_cleaning_encoders='/content/drive/MyDrive/NLP_Chatbot_Capstone_Project/Cleaning Encoders'\r\n",
        "path_tf_idf_vectorizer='/content/drive/MyDrive/NLP_Chatbot_Capstone_Project/Trained TF-IDF Vectorizer '\r\n",
        "path_default_classifiers='/content/drive/MyDrive/NLP_Chatbot_Capstone_Project/Trained Default Machine Learning Classifiers'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX7jRxCs8ZOA"
      },
      "source": [
        "encoded_test_entry=temp_test_entry"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okctuid48G5z"
      },
      "source": [
        "### **Initial Encoders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwByBLjKJcC7",
        "outputId": "152c6927-133c-4719-c92b-3ec26c328960"
      },
      "source": [
        "files=[f for f in listdir(path_initial_encoders) if isfile(join(path_initial_encoders, f))]\r\n",
        "files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ordinal Encoder_Accident Level',\n",
              " 'Ordinal Encoder_Year of Incident',\n",
              " 'Ordinal Encoder_Date of Incident',\n",
              " 'Ordinal Encoder_Month of Incident',\n",
              " 'Label Encoder_Day of Incident']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbstrEFQyNm2",
        "outputId": "da3cac62-121d-470f-8b2c-7e9772690742"
      },
      "source": [
        "files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ordinal Encoder_Accident Level',\n",
              " 'Ordinal Encoder_Year of Incident',\n",
              " 'Ordinal Encoder_Date of Incident',\n",
              " 'Ordinal Encoder_Month of Incident',\n",
              " 'Label Encoder_Day of Incident']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdL8c-KQALV8"
      },
      "source": [
        "ordinal_encoded_features=[]\r\n",
        "label_encoded_features=[]\r\n",
        "binary_encoded_features=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfUoijzWJcAF",
        "outputId": "91c5b6ae-b237-412a-fc5e-bf78e33e020f"
      },
      "source": [
        "for i in range(0,len(files)):\r\n",
        "  with open(path_initial_encoders+'/'+files[i] ,'rb') as f:\r\n",
        "    encoder=pickle.load(f)\r\n",
        "  if files[i]=='Ordinal Encoder_Accident Level':\r\n",
        "    final_encoder=encoder\r\n",
        "  feature_name=files[i].split('_')[1].strip()\r\n",
        "  if files[i].split('_')[0].strip().__contains__('Label'):\r\n",
        "    encoded_test_entry[feature_name]=encoder.transform(np.array(temp_test_entry[feature_name]).reshape(-1,1))[0]\r\n",
        "    label_encoded_features.append(feature_name)\r\n",
        "    # print(encoder.classes_)\r\n",
        "  elif files[i].split('_')[0].strip().__contains__('Ordinal'):\r\n",
        "    if feature_name=='Accident Level':\r\n",
        "      continue\r\n",
        "    else:\r\n",
        "      encoded_test_entry[feature_name]=encoder.transform(np.array(temp_test_entry[feature_name]).reshape(-1,1))[0][0]\r\n",
        "      ordinal_encoded_features.append(feature_name)\r\n",
        "      # print(encoder.categories_)\r\n",
        "  else:\r\n",
        "    continue\r\n",
        "encoded_test_entry"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Countries': 'Country_01',\n",
              " 'Critical Risk': 'Pressed',\n",
              " 'Data': '2016-01-01  12:00:00',\n",
              " 'Date of Incident': 0.0,\n",
              " 'Date of Incidents': datetime.datetime(2016, 1, 1, 12, 0),\n",
              " 'Day of Incident': 0,\n",
              " 'Description': 'While removing the drill rod of the Jumbo 08 for maintenance, the supervisor proceeds to loosen the support of the intermediate centralizer to facilitate the removal, seeing this the mechanic supports one end on the drill of the equipment to pull with both hands the bar and accelerate the removal from this, at this moment the bar slides from its point of support and tightens the fingers of the mechanic between the drilling bar and the beam of the jumbo.',\n",
              " 'Employee or Third Party': 'Third Party',\n",
              " 'Genre': 'Male',\n",
              " 'Industry Sector': 'Mining',\n",
              " 'Local': 'Local_01',\n",
              " 'Month of Incident': 0.0,\n",
              " 'Potential Accident Level': 'IV',\n",
              " 'Year of Incident': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngkZ6-XR8M1C"
      },
      "source": [
        "### **Cleaning Encoders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwHLvA1Y8OX6",
        "outputId": "68be64ea-80a0-4771-dd5d-9e8cf6630c1d"
      },
      "source": [
        "files=[f for f in listdir(path_cleaning_encoders) if isfile(join(path_cleaning_encoders, f))]\r\n",
        "files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ordinal Encoder_Potential Accident Level',\n",
              " 'Label Encoder_Employee or Third Party',\n",
              " 'Label Encoder_Genre',\n",
              " 'Label Encoder_Countries',\n",
              " 'Label Encoder_Industry Sector',\n",
              " 'Binary Encoder_Local',\n",
              " 'Scaler_Potential Accident Level']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1456Og7h8OlJ",
        "outputId": "d782f314-24cc-4605-bade-cb66decad503"
      },
      "source": [
        "for i in range(0,len(files)):\r\n",
        "  print(files[i])\r\n",
        "  with open(path_cleaning_encoders+'/'+files[i] ,'rb') as f:\r\n",
        "    encoder=pickle.load(f)\r\n",
        "  feature_name=files[i].split('_')[1].strip()\r\n",
        "  if files[i].split('_')[0].strip().__contains__('Label'):\r\n",
        "    # print(feature_name,temp_test_entry[feature_name])\r\n",
        "    # print(encoder.transform(np.array(temp_test_entry[feature_name]).reshape(-1,1)))    \r\n",
        "    encoded_test_entry[feature_name]=encoder.transform(np.array(temp_test_entry[feature_name]).reshape(-1,1))[0]\r\n",
        "    label_encoded_features.append(feature_name)\r\n",
        "    # print(encoder.classes_)\r\n",
        "  elif files[i].split('_')[0].strip().__contains__('Ordinal'):\r\n",
        "    # print(feature_name,temp_test_entry[feature_name])\r\n",
        "    # print(encoder.transform(np.array(temp_test_entry[feature_name]).reshape(-1,1)))\r\n",
        "    encoded_test_entry[feature_name]=encoder.transform(np.array(temp_test_entry[feature_name]).reshape(-1,1))[0][0]\r\n",
        "    ordinal_encoded_features.append(feature_name)\r\n",
        "    # print(encoder.categories_)\r\n",
        "  elif files[i].split('_')[0].strip().__contains__('Binary'):\r\n",
        "    binary_encoder=encoder\r\n",
        "  elif files[i].split('_')[0].strip().__contains__('Scaler'):\r\n",
        "    # print(feature_name)\r\n",
        "    value=(np.array([encoded_test_entry['Potential Accident Level']]).reshape(-1,1))\r\n",
        "    encoded_test_entry['Potential Accident Level']=encoder.transform(value)[0][0]\r\n",
        "  else:\r\n",
        "    continue"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ordinal Encoder_Potential Accident Level\n",
            "Label Encoder_Employee or Third Party\n",
            "Label Encoder_Genre\n",
            "Label Encoder_Countries\n",
            "Label Encoder_Industry Sector\n",
            "Binary Encoder_Local\n",
            "Scaler_Potential Accident Level\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69oWoLQA8Oan"
      },
      "source": [
        "# y=encoded_test_entry['Accident Level']\r\n",
        "# del encoded_test_entry['Accident Level']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amJecOKMHYCc",
        "outputId": "833d8817-3ea8-4b7f-8ad8-f06be17dc61b"
      },
      "source": [
        "encoded_test_entry['index']=0\r\n",
        "temp=[]\r\n",
        "for i in list(encoded_test_entry.keys()):\r\n",
        "  temp.append(encoded_test_entry[i])\r\n",
        "temp=pd.DataFrame(np.array([temp]),columns=list(encoded_test_entry.keys()))\r\n",
        "temp.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Description', 'Critical Risk', 'Data', 'Countries', 'Local',\n",
              "       'Industry Sector', 'Genre', 'Employee or Third Party',\n",
              "       'Potential Accident Level', 'Date of Incidents', 'Year of Incident',\n",
              "       'Month of Incident', 'Date of Incident', 'Day of Incident', 'index'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgcewzXjJZT_"
      },
      "source": [
        "encodings=binary_encoder.transform(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSoMhaMwKnvW"
      },
      "source": [
        "### **TF-IDF Vectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XVTbPBXKZAt",
        "outputId": "3a07d355-bb8b-4e06-952a-ee94745cba73"
      },
      "source": [
        "files=[f for f in listdir(path_tf_idf_vectorizer) if isfile(join(path_tf_idf_vectorizer, f))]\r\n",
        "files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Train_Set_1_TF_IDF_Vectorizer',\n",
              " 'Train_Set_2_TF_IDF_Vectorizer',\n",
              " 'Train_Set_3_TF_IDF_Vectorizer',\n",
              " 'Train_Set_4_TF_IDF_Vectorizer',\n",
              " 'Train_Set_5_TF_IDF_Vectorizer',\n",
              " 'Train_Set_6_TF_IDF_Vectorizer',\n",
              " 'Train_Set_7_TF_IDF_Vectorizer',\n",
              " 'Train_Set_8_TF_IDF_Vectorizer',\n",
              " 'Train_Set_9_TF_IDF_Vectorizer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqm-FZl5RPlI"
      },
      "source": [
        "stop_words = list(stopwords.words('english'))\r\n",
        "punctuations = list(string.punctuation)\r\n",
        "stop_words_list = stop_words+punctuations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suq0Vo6GMzha"
      },
      "source": [
        "def clean_text(text):\r\n",
        "      text = text.lower()\r\n",
        "      pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\r\n",
        "      text = pattern.sub('', text)\r\n",
        "      text = \" \".join(filter(lambda x:x[0]!='@', text.split()))\r\n",
        "      emoji = re.compile(\"[\"\r\n",
        "                            u\"\\U0001F600-\\U0001FFFF\"  # emoticons\r\n",
        "                            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\r\n",
        "                            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\r\n",
        "                            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\r\n",
        "                            u\"\\U00002702-\\U000027B0\"\r\n",
        "                            u\"\\U000024C2-\\U0001F251\"\r\n",
        "                            \"]+\", flags=re.UNICODE)\r\n",
        "      \r\n",
        "      text = emoji.sub(r'', text)\r\n",
        "      text = text.lower()\r\n",
        "      text = re.sub(r\"i'm\", \"i am\", text)\r\n",
        "      text = re.sub(r\"he's\", \"he is\", text)\r\n",
        "      text = re.sub(r\"she's\", \"she is\", text)\r\n",
        "      text = re.sub(r\"that's\", \"that is\", text)        \r\n",
        "      text = re.sub(r\"what's\", \"what is\", text)\r\n",
        "      text = re.sub(r\"where's\", \"where is\", text) \r\n",
        "      text = re.sub(r\"\\'ll\", \" will\", text)  \r\n",
        "      text = re.sub(r\"\\'ve\", \" have\", text)  \r\n",
        "      text = re.sub(r\"\\'re\", \" are\", text)\r\n",
        "      text = re.sub(r\"\\'d\", \" would\", text)\r\n",
        "      text = re.sub(r\"\\'ve\", \" have\", text)\r\n",
        "      text = re.sub(r\"won't\", \"will not\", text)\r\n",
        "      text = re.sub(r\"don't\", \"do not\", text)\r\n",
        "      text = re.sub(r\"did't\", \"did not\", text)\r\n",
        "      text = re.sub(r\"can't\", \"can not\", text)\r\n",
        "      text = re.sub(r\"it's\", \"it is\", text)\r\n",
        "      text = re.sub(r\"couldn't\", \"could not\", text)\r\n",
        "      text = re.sub(r\"have't\", \"have not\", text)\r\n",
        "      text = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-]\", \"\", text)\r\n",
        "      return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uonmzBzTPM6t"
      },
      "source": [
        "encodings['Merged_Description']=encodings['Critical Risk']+encodings['Description']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksU5c8KbKY9p"
      },
      "source": [
        "with open(path_tf_idf_vectorizer+'/'+files[0],'rb') as f:\r\n",
        "  tf_idf_vec=pickle.load(f)\r\n",
        "encodings['Clean Words']=(clean_text(\" \".join([w for w in word_tokenize(encodings['Description'][0]) if not w in stop_words_list])))\r\n",
        "words_transformed_test=tf_idf_vec.transform(encodings['Clean Words'])\r\n",
        "encoded_bag_of_words_model=pd.DataFrame(words_transformed_test.todense(),columns=['word_'+str(i)+'_'+tf_idf_vec.get_feature_names()[i] for i in range(0,words_transformed_test.todense().shape[1])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX7nIQIrKY6a"
      },
      "source": [
        "final_dataframe=pd.concat([encodings,encoded_bag_of_words_model],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r94e1R8mPAQV"
      },
      "source": [
        "columns_to_delete=['Critical Risk','Description','Data','Date of Incidents','Merged_Description','index','Clean Words']\r\n",
        "for j in columns_to_delete:\r\n",
        "  del final_dataframe[j]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKknfwz4Pi90"
      },
      "source": [
        "### **Modelling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_6FradYVPraP",
        "outputId": "faa329d3-4ac4-4492-81a8-f2510b6279b1"
      },
      "source": [
        "files=[f for f in listdir(path_default_classifiers) if isfile(join(path_default_classifiers, f))]\r\n",
        "files[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Model_Random Forest Default'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW4CJE3QPj_E"
      },
      "source": [
        "with open(path_default_classifiers+'/'+files[5],'rb') as f:\r\n",
        "  random_forest=pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTrZjmqOPj8m"
      },
      "source": [
        "prediction=random_forest.predict(final_dataframe.iloc[0].values.reshape(1,-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcEpqv49Pj5h"
      },
      "source": [
        "predicted_class=final_encoder.inverse_transform([prediction])[0][0]\r\n",
        "# predicted_class,final_encoder.inverse_transform([[y]])[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "noRQwsbT2Ae0",
        "outputId": "931791f5-6e70-4b47-9fca-83c72bc9074f"
      },
      "source": [
        "predicted_class"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    }
  ]
}
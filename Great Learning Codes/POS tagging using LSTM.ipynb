{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proprietary content. Â©Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N7afQbd39ARc"
   },
   "source": [
    "### Libraries along with their versions used at the time of making notebook-\n",
    "google\t2.0.3\n",
    "\n",
    "nltk\t3.2.5\n",
    "\n",
    "numpy\t1.18.1\n",
    "\n",
    "pandas\t0.25.3\n",
    "\n",
    "tensorflow\t2.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZOk8Eu4_t70R"
   },
   "source": [
    "Firstly, let's select TensorFlow version 2.x in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 988,
     "status": "ok",
     "timestamp": 1581775238262,
     "user": {
      "displayName": "Suryansh Sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64",
      "userId": "03232072030227591914"
     },
     "user_tz": -330
    },
    "id": "H6RZUm0p4wYJ",
    "outputId": "a598c97a-63ce-4c39-a1d0-595975c7c506"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TWi96z-8SyX0"
   },
   "outputs": [],
   "source": [
    "# Initialize the random number generator\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "# Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OKVkkLaLdPGU"
   },
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JK0ZRJoxhrFe"
   },
   "source": [
    "As we are using google colab, we need to mount the google drive to load the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 960,
     "status": "ok",
     "timestamp": 1581775244188,
     "user": {
      "displayName": "Suryansh Sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64",
      "userId": "03232072030227591914"
     },
     "user_tz": -330
    },
    "id": "dv6RCAcGLd4w",
    "outputId": "ce5f2ae6-2bd9-4f17-9ea1-a326cf53775d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lDTL5oRkmJK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# IMPORT DATA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('/content/drive/My Drive/NLP/ner_dataset.csv', encoding='latin1')\n",
    "data = data.fillna(method=\"ffill\") # Deal with N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LrZ4pIhxkmJP"
   },
   "outputs": [],
   "source": [
    "tags = list(set(data[\"POS\"].values)) # Read POS values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 752
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1184,
     "status": "ok",
     "timestamp": 1581775358900,
     "user": {
      "displayName": "Suryansh Sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64",
      "userId": "03232072030227591914"
     },
     "user_tz": -330
    },
    "id": "y5dLVpx-kmJS",
    "outputId": "bde09fb2-6258-4263-9697-86a80eff2a79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RBR',\n",
       " 'RRB',\n",
       " 'VBZ',\n",
       " 'WRB',\n",
       " 'VBD',\n",
       " 'PRP$',\n",
       " 'VBN',\n",
       " 'NN',\n",
       " '$',\n",
       " 'FW',\n",
       " 'RB',\n",
       " 'JJS',\n",
       " 'NNP',\n",
       " 'NNPS',\n",
       " 'NNS',\n",
       " 'VBG',\n",
       " ':',\n",
       " 'RBS',\n",
       " '``',\n",
       " 'WP',\n",
       " 'TO',\n",
       " ';',\n",
       " 'UH',\n",
       " 'VBP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'PDT',\n",
       " 'LRB',\n",
       " 'WDT',\n",
       " 'CD',\n",
       " 'IN',\n",
       " 'JJR',\n",
       " 'POS',\n",
       " 'WP$',\n",
       " 'JJ',\n",
       " 'DT',\n",
       " 'EX',\n",
       " 'RP',\n",
       " ',',\n",
       " '.',\n",
       " 'CC',\n",
       " 'PRP']"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags # List of possible POS values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kla7rPZ4kmJV"
   },
   "outputs": [],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"DUMMY\") # Add a dummy word to pad sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0quKyRPkmJY"
   },
   "outputs": [],
   "source": [
    "# Code to read sentences\n",
    "\n",
    "class ReadSentences(object): \n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5RMj10qkmJa"
   },
   "outputs": [],
   "source": [
    "sentences = ReadSentences(data).sentences # Read all sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7CEvxwAkmJe"
   },
   "outputs": [],
   "source": [
    "# Convert words and tags into numbers\n",
    "word2id = {w: i for i, w in enumerate(words)}\n",
    "tag2id = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BHnxkCxTkmJh"
   },
   "outputs": [],
   "source": [
    "# Prepare input and output data\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_len = 50\n",
    "X = [[word2id[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=len(words)-1)\n",
    "y = [[tag2id[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2id[\".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-R4K9GikmJn"
   },
   "outputs": [],
   "source": [
    "# Convert output to one-hot bit\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=len(tags)) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1225,
     "status": "ok",
     "timestamp": 1581775497017,
     "user": {
      "displayName": "Suryansh Sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64",
      "userId": "03232072030227591914"
     },
     "user_tz": -330
    },
    "id": "oAur07mkkmJq",
    "outputId": "cc135f05-6e40-4e32-badb-63e1b1c2ad68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNDkmkAkkmJw"
   },
   "outputs": [],
   "source": [
    "# Training and test split by sentences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PHFx7nojkmJy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cc1Ss7aVkmJ0"
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(max_len,)) # Input layer\n",
    "model = Embedding(input_dim=len(words), output_dim=50, input_length=max_len)(input) # Word embedding layer\n",
    "model = Dropout(0.1)(model) # Dropout\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model) # Bi-directional LSTM layer\n",
    "out = TimeDistributed(Dense(len(tags), activation=\"softmax\"))(model)  # softmax output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LDIws8lAkmJ3"
   },
   "outputs": [],
   "source": [
    "model = Model(input, out) # Complete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-j6oKch0kmJ5"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) # Compile with an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 493344,
     "status": "ok",
     "timestamp": 1581775992888,
     "user": {
      "displayName": "Suryansh Sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64",
      "userId": "03232072030227591914"
     },
     "user_tz": -330
    },
    "id": "QATrRFNAkmJ8",
    "outputId": "3c8fd630-372f-4200-8654-726da39ea2b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34530 samples, validate on 3837 samples\n",
      "Epoch 1/3\n",
      "34530/34530 [==============================] - 166s 5ms/sample - loss: 0.3817 - accuracy: 0.8964 - val_loss: 0.0707 - val_accuracy: 0.9794\n",
      "Epoch 2/3\n",
      "34530/34530 [==============================] - 161s 5ms/sample - loss: 0.0518 - accuracy: 0.9850 - val_loss: 0.0450 - val_accuracy: 0.9864\n",
      "Epoch 3/3\n",
      "34530/34530 [==============================] - 165s 5ms/sample - loss: 0.0353 - accuracy: 0.9898 - val_loss: 0.0380 - val_accuracy: 0.9884\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=3, validation_split=0.1, verbose=1) # Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 892
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 493034,
     "status": "ok",
     "timestamp": 1581775993240,
     "user": {
      "displayName": "Suryansh Sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64",
      "userId": "03232072030227591914"
     },
     "user_tz": -330
    },
    "id": "JZI4x1DgkmKA",
    "outputId": "5ee87eb8-e73d-4d94-b7ff-4487d6dbe5ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The                  -- DT\n",
      "Gilbert              -- NNP\n",
      "Islands              -- NNP\n",
      "were                 -- VBD\n",
      "granted              -- VBN\n",
      "self-rule            -- NN\n",
      "by                   -- IN\n",
      "the                  -- DT\n",
      "UK                   -- NNP\n",
      "in                   -- IN\n",
      "1971                 -- CD\n",
      "and                  -- CC\n",
      "complete             -- JJ\n",
      "independence         -- NN\n",
      "in                   -- IN\n",
      "1979                 -- CD\n",
      "under                -- IN\n",
      "the                  -- DT\n",
      "new                  -- JJ\n",
      "name                 -- NN\n",
      "of                   -- IN\n",
      "Kiribati             -- NNP\n",
      ".                    -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n"
     ]
    }
   ],
   "source": [
    "# Demo test on one sample. See how it is mostly correct, but not 100%\n",
    "\n",
    "i = 1213 # Some test sentence sample\n",
    "p = model.predict(np.array([X_te[i]])) # Predict on it\n",
    "p = np.argmax(p, axis=-1) # Map softmax back to a POS index\n",
    "for w, pred in zip(X_te[i], p[0]): # for every word in the sentence\n",
    "    print(\"{:20} -- {}\".format(words[w], tags[pred])) # Print word and tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1167,
     "status": "ok",
     "timestamp": 1581776185288,
     "user": {
      "displayName": "Suryansh Sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64",
      "userId": "03232072030227591914"
     },
     "user_tz": -330
    },
    "id": "l7FYeWwmqp8u",
    "outputId": "71668428-bd97-4545-b4e0-ca042060b2bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBTSn305kmKD"
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "sentence = nltk.word_tokenize('That was a nice jump')\n",
    "X_Samp = pad_sequences(maxlen=max_len, sequences=[[word2id[word] for word in sentence]], padding=\"post\", value=len(words)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 892
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 492052,
     "status": "ok",
     "timestamp": 1581775994098,
     "user": {
      "displayName": "Suryansh Sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64",
      "userId": "03232072030227591914"
     },
     "user_tz": -330
    },
    "id": "qlLPSYujkmKH",
    "outputId": "a4a16f45-3818-43ad-d52a-01bc07f1e3f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That                 -- DT\n",
      "was                  -- VBD\n",
      "a                    -- DT\n",
      "nice                 -- JJ\n",
      "jump                 -- NN\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(np.array([X_Samp[0]])) # Predict on it\n",
    "p = np.argmax(p, axis=-1) # Map softmax back to a POS index\n",
    "for w, pred in zip(X_Samp[0], p[0]): # for every word in the sentence\n",
    "    print(\"{:20} -- {}\".format(words[w], tags[pred])) # Print word and tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWVnTDL-HnFg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "POS tagging using LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
